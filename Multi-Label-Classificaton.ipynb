{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code For the CSV Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T12:02:03.139378Z",
     "iopub.status.busy": "2025-03-25T12:02:03.138999Z",
     "iopub.status.idle": "2025-03-25T12:02:03.977858Z",
     "shell.execute_reply": "2025-03-25T12:02:03.976730Z",
     "shell.execute_reply.started": "2025-03-25T12:02:03.139344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV saved successfully at: /kaggle/working/New_Main.csv\n",
      "                           name                            image name  \\\n",
      "0  black_checkered_casual_shirt  black_checkered_casual_shirt_100.jpg   \n",
      "1  black_checkered_casual_shirt  black_checkered_casual_shirt_102.jpg   \n",
      "2  black_checkered_casual_shirt  black_checkered_casual_shirt_104.jpg   \n",
      "3  black_checkered_casual_shirt  black_checkered_casual_shirt_106.jpg   \n",
      "4  black_checkered_casual_shirt  black_checkered_casual_shirt_108.jpg   \n",
      "\n",
      "                                          image path  \\\n",
      "0  /kaggle/input/apparel-dataset-test/ALL IMAGES/...   \n",
      "1  /kaggle/input/apparel-dataset-test/ALL IMAGES/...   \n",
      "2  /kaggle/input/apparel-dataset-test/ALL IMAGES/...   \n",
      "3  /kaggle/input/apparel-dataset-test/ALL IMAGES/...   \n",
      "4  /kaggle/input/apparel-dataset-test/ALL IMAGES/...   \n",
      "\n",
      "                     attributes  \n",
      "0  black,checkered,casual,shirt  \n",
      "1  black,checkered,casual,shirt  \n",
      "2  black,checkered,casual,shirt  \n",
      "3  black,checkered,casual,shirt  \n",
      "4  black,checkered,casual,shirt  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "local_csv = r\"/kaggle/input/apparel-dataset-test/NEW_Main.csv\"  # Read-only CSV\n",
    "kaggle_csv = r\"/kaggle/working/New_Main.csv\"  # New CSV for Kaggle\n",
    "\n",
    "# Load the CSV in read-only mode\n",
    "df = pd.read_csv(local_csv)\n",
    "\n",
    "# Path correction logic\n",
    "kaggle_base_path = \"/kaggle/input/apparel-dataset-test/ALL IMAGES/ALL IMAGES\"\n",
    "\n",
    "# Update paths\n",
    "df[\"image path\"] = df.apply(\n",
    "    lambda row: f\"{kaggle_base_path}/{row['name']}/{row['image name']}\", axis=1\n",
    ")\n",
    "\n",
    "# Save the updated CSV for Kaggle\n",
    "df.to_csv(kaggle_csv, index=False)\n",
    "\n",
    "print(f\"✅ CSV saved successfully at: {kaggle_csv}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T12:02:22.190083Z",
     "iopub.status.busy": "2025-03-25T12:02:22.189733Z",
     "iopub.status.idle": "2025-03-25T12:02:22.200510Z",
     "shell.execute_reply": "2025-03-25T12:02:22.199805Z",
     "shell.execute_reply.started": "2025-03-25T12:02:22.190050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>image name</th>\n",
       "      <th>image path</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>black_checkered_casual_shirt</td>\n",
       "      <td>black_checkered_casual_shirt_100.jpg</td>\n",
       "      <td>/kaggle/input/apparel-dataset-test/ALL IMAGES/...</td>\n",
       "      <td>black,checkered,casual,shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>black_checkered_casual_shirt</td>\n",
       "      <td>black_checkered_casual_shirt_102.jpg</td>\n",
       "      <td>/kaggle/input/apparel-dataset-test/ALL IMAGES/...</td>\n",
       "      <td>black,checkered,casual,shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>black_checkered_casual_shirt</td>\n",
       "      <td>black_checkered_casual_shirt_104.jpg</td>\n",
       "      <td>/kaggle/input/apparel-dataset-test/ALL IMAGES/...</td>\n",
       "      <td>black,checkered,casual,shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>black_checkered_casual_shirt</td>\n",
       "      <td>black_checkered_casual_shirt_106.jpg</td>\n",
       "      <td>/kaggle/input/apparel-dataset-test/ALL IMAGES/...</td>\n",
       "      <td>black,checkered,casual,shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>black_checkered_casual_shirt</td>\n",
       "      <td>black_checkered_casual_shirt_108.jpg</td>\n",
       "      <td>/kaggle/input/apparel-dataset-test/ALL IMAGES/...</td>\n",
       "      <td>black,checkered,casual,shirt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name                            image name  \\\n",
       "0  black_checkered_casual_shirt  black_checkered_casual_shirt_100.jpg   \n",
       "1  black_checkered_casual_shirt  black_checkered_casual_shirt_102.jpg   \n",
       "2  black_checkered_casual_shirt  black_checkered_casual_shirt_104.jpg   \n",
       "3  black_checkered_casual_shirt  black_checkered_casual_shirt_106.jpg   \n",
       "4  black_checkered_casual_shirt  black_checkered_casual_shirt_108.jpg   \n",
       "\n",
       "                                          image path  \\\n",
       "0  /kaggle/input/apparel-dataset-test/ALL IMAGES/...   \n",
       "1  /kaggle/input/apparel-dataset-test/ALL IMAGES/...   \n",
       "2  /kaggle/input/apparel-dataset-test/ALL IMAGES/...   \n",
       "3  /kaggle/input/apparel-dataset-test/ALL IMAGES/...   \n",
       "4  /kaggle/input/apparel-dataset-test/ALL IMAGES/...   \n",
       "\n",
       "                     attributes  \n",
       "0  black,checkered,casual,shirt  \n",
       "1  black,checkered,casual,shirt  \n",
       "2  black,checkered,casual,shirt  \n",
       "3  black,checkered,casual,shirt  \n",
       "4  black,checkered,casual,shirt  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Dependancies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T12:02:56.541281Z",
     "iopub.status.busy": "2025-03-25T12:02:56.540909Z",
     "iopub.status.idle": "2025-03-25T12:02:59.653206Z",
     "shell.execute_reply": "2025-03-25T12:02:59.652065Z",
     "shell.execute_reply.started": "2025-03-25T12:02:56.541248Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Images and CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T12:03:01.966052Z",
     "iopub.status.busy": "2025-03-25T12:03:01.965592Z",
     "iopub.status.idle": "2025-03-25T12:03:01.969830Z",
     "shell.execute_reply": "2025-03-25T12:03:01.968798Z",
     "shell.execute_reply.started": "2025-03-25T12:03:01.966025Z"
    }
   },
   "outputs": [],
   "source": [
    "csv_path = r\"/kaggle/working/New_Main.csv\"\n",
    "root_dir = r\"/kaggle/input/apparel-dataset-test/ALL IMAGES/ALL IMAGES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T12:03:03.324692Z",
     "iopub.status.busy": "2025-03-25T12:03:03.324387Z",
     "iopub.status.idle": "2025-03-25T12:03:03.437286Z",
     "shell.execute_reply": "2025-03-25T12:03:03.436596Z",
     "shell.execute_reply.started": "2025-03-25T12:03:03.324669Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(csv_path, on_bad_lines='skip')\n",
    "data = data.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T12:03:05.000046Z",
     "iopub.status.busy": "2025-03-25T12:03:04.999736Z",
     "iopub.status.idle": "2025-03-25T12:03:05.005468Z",
     "shell.execute_reply": "2025-03-25T12:03:05.004434Z",
     "shell.execute_reply.started": "2025-03-25T12:03:05.000021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total classes: 21\n"
     ]
    }
   ],
   "source": [
    "colors = ['white', 'blue', 'black', 'red', 'green','brown']\n",
    "types = [\"t-shirt\", \"shirt\", \"polo\", \"formal shirt\", \"casual shirt\",\"dress\",\"pants\",\"shoes\",\"shorts\"]\n",
    "patterns = [\"plain\", \"checkered\", \"striped\", \"floral\", \"dotted\", \"printed\"]\n",
    "classes = colors + types + patterns\n",
    "print(\"Total classes:\", len(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode and Decode Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T12:03:06.913551Z",
     "iopub.status.busy": "2025-03-25T12:03:06.913178Z",
     "iopub.status.idle": "2025-03-25T12:03:07.783576Z",
     "shell.execute_reply": "2025-03-25T12:03:07.782756Z",
     "shell.execute_reply.started": "2025-03-25T12:03:06.913523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         attributes  \\\n",
      "0      black,checkered,casual,shirt   \n",
      "1      black,checkered,casual,shirt   \n",
      "2      black,checkered,casual,shirt   \n",
      "3      black,checkered,casual,shirt   \n",
      "4      black,checkered,casual,shirt   \n",
      "...                             ...   \n",
      "37713         white,striped,t-shirt   \n",
      "37714         white,striped,t-shirt   \n",
      "37715         white,striped,t-shirt   \n",
      "37716         white,striped,t-shirt   \n",
      "37717         white,striped,t-shirt   \n",
      "\n",
      "                                          encoded_target  \n",
      "0      [tensor(0.), tensor(0.), tensor(1.), tensor(0....  \n",
      "1      [tensor(0.), tensor(0.), tensor(1.), tensor(0....  \n",
      "2      [tensor(0.), tensor(0.), tensor(1.), tensor(0....  \n",
      "3      [tensor(0.), tensor(0.), tensor(1.), tensor(0....  \n",
      "4      [tensor(0.), tensor(0.), tensor(1.), tensor(0....  \n",
      "...                                                  ...  \n",
      "37713  [tensor(1.), tensor(0.), tensor(0.), tensor(0....  \n",
      "37714  [tensor(1.), tensor(0.), tensor(0.), tensor(0....  \n",
      "37715  [tensor(1.), tensor(0.), tensor(0.), tensor(0....  \n",
      "37716  [tensor(1.), tensor(0.), tensor(0.), tensor(0....  \n",
      "37717  [tensor(1.), tensor(0.), tensor(0.), tensor(0....  \n",
      "\n",
      "[37718 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function to encode labels from CSV\n",
    "def encode_label(label, classes_list=classes):\n",
    "    target = torch.zeros(len(classes_list))\n",
    "    for l in label.split(\",\"):  # Ensure proper splitting by comma\n",
    "        l = l.strip()  # Remove any leading/trailing spaces\n",
    "        if l in classes_list:\n",
    "            idx = classes_list.index(l)\n",
    "            target[idx] = 1\n",
    "    return target\n",
    "\n",
    "# Apply encoding to the dataset\n",
    "data[\"encoded_target\"] = data[\"attributes\"].apply(encode_label)\n",
    "\n",
    "# Decode labels for verification\n",
    "def decode_target(target, threshold=0.4):\n",
    "    result = []\n",
    "    for i, x in enumerate(target):\n",
    "        if x >= threshold:\n",
    "            result.append(classes[i])\n",
    "    return result\n",
    "\n",
    "# Verify the encoding\n",
    "print(data[[\"attributes\", \"encoded_target\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T12:03:11.714062Z",
     "iopub.status.busy": "2025-03-25T12:03:11.713734Z",
     "iopub.status.idle": "2025-03-25T12:03:11.718643Z",
     "shell.execute_reply": "2025-03-25T12:03:11.717746Z",
     "shell.execute_reply.started": "2025-03-25T12:03:11.714032Z"
    }
   },
   "outputs": [],
   "source": [
    "imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "transform = T.Compose([\n",
    "    T.Resize((128, 128)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomRotation(2),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(*imagenet_stats)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T12:03:13.618794Z",
     "iopub.status.busy": "2025-03-25T12:03:13.618459Z",
     "iopub.status.idle": "2025-03-25T12:03:13.625426Z",
     "shell.execute_reply": "2025-03-25T12:03:13.624567Z",
     "shell.execute_reply.started": "2025-03-25T12:03:13.618764Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, root_dir, transform=None):\n",
    "        self.data = data\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data.iloc[idx]['image path'].strip()\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "\n",
    "        # Check if image exists\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"Missing image: {img_path}\")\n",
    "            return torch.zeros(3, 128, 128), torch.zeros(len(classes))  \n",
    "\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            return torch.zeros(3, 128, 128), torch.zeros(len(classes))  \n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # Get label from CSV\n",
    "        label = self.data.iloc[idx][\"encoded_target\"]\n",
    "\n",
    "        # Ensure label is a tensor\n",
    "        if isinstance(label, str):\n",
    "            label = torch.tensor(eval(label), dtype=torch.float32)  \n",
    "        else:\n",
    "            label = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T12:03:21.086607Z",
     "iopub.status.busy": "2025-03-25T12:03:21.086278Z",
     "iopub.status.idle": "2025-03-25T12:07:57.809672Z",
     "shell.execute_reply": "2025-03-25T12:07:57.808861Z",
     "shell.execute_reply.started": "2025-03-25T12:03:21.086581Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = MyDataset(data, root_dir, transform=transform)\n",
    "train_ds, val_ds = train_test_split(dataset, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T12:08:35.838936Z",
     "iopub.status.busy": "2025-03-25T12:08:35.838618Z",
     "iopub.status.idle": "2025-03-25T12:08:35.843474Z",
     "shell.execute_reply": "2025-03-25T12:08:35.842422Z",
     "shell.execute_reply.started": "2025-03-25T12:08:35.838912Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T12:08:42.564149Z",
     "iopub.status.busy": "2025-03-25T12:08:42.563814Z",
     "iopub.status.idle": "2025-03-25T12:08:42.572452Z",
     "shell.execute_reply": "2025-03-25T12:08:42.571491Z",
     "shell.execute_reply.started": "2025-03-25T12:08:42.564118Z"
    }
   },
   "outputs": [],
   "source": [
    "def F_score(output, label, threshold=0.7, beta=1):  \n",
    "    prob = output > threshold\n",
    "    label = label > threshold\n",
    "\n",
    "    TP = (prob & label).sum(1).float()\n",
    "    FP = (prob & (~label)).sum(1).float()\n",
    "    FN = ((~prob) & label).sum(1).float()\n",
    "\n",
    "    precision = torch.mean(TP / (TP + FP + 1e-12))\n",
    "    recall = torch.mean(TP / (TP + FN + 1e-12))\n",
    "    F2 = (1 + beta**2) * precision * recall / (beta**2 * precision + recall + 1e-12)\n",
    "    return F2.mean(0)\n",
    "\n",
    "# Model Training Base Class\n",
    "class MultilabelImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, targets = batch \n",
    "        out = self(images)                            \n",
    "        loss = F.binary_cross_entropy(out, targets)   \n",
    "        return loss    \n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        images, targets = batch \n",
    "        out = self(images)                           \n",
    "        loss = F.binary_cross_entropy(out, targets)  \n",
    "        score = F_score(out, targets)                \n",
    "        return {'val_loss': loss.detach(), 'val_score': score.detach()}      \n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()       \n",
    "        batch_scores = [x['val_score'] for x in outputs]    \n",
    "        epoch_score = torch.stack(batch_scores).mean()      \n",
    "        return {'val_loss': epoch_loss.item(), 'val_score': epoch_score.item()}    \n",
    "\n",
    "    def epoch_end(self, epoch, result):                     \n",
    "        print(\"Epoch [{}], last_lr: {:.4f}, train_loss: {:.4f}, val_loss: {:.4f}, val_score: {:.4f}\".format(\n",
    "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resnet15 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T12:08:49.540073Z",
     "iopub.status.busy": "2025-03-25T12:08:49.539746Z",
     "iopub.status.idle": "2025-03-25T12:08:49.549394Z",
     "shell.execute_reply": "2025-03-25T12:08:49.548408Z",
     "shell.execute_reply.started": "2025-03-25T12:08:49.540047Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResNet15(MultilabelImageClassificationBase):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()     \n",
    "        # Input 3 x 128 x 128\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.res1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(4),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.res2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 512, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(4),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.res3 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(4),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.res4 = nn.Sequential(\n",
    "            nn.Conv2d(1024, 1024, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024 * 1 * 1, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv2(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.res3(out) + out\n",
    "        out = self.conv4(out)\n",
    "        out = self.res4(out) + out\n",
    "        out = self.classifier(out)\n",
    "        out = torch.sigmoid(out)  # Use sigmoid for multi-label classification\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T12:08:57.137086Z",
     "iopub.status.busy": "2025-03-25T12:08:57.136661Z",
     "iopub.status.idle": "2025-03-25T12:08:57.591093Z",
     "shell.execute_reply": "2025-03-25T12:08:57.590302Z",
     "shell.execute_reply.started": "2025-03-25T12:08:57.137049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNet15(3, len(classes)).to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T12:09:04.053842Z",
     "iopub.status.busy": "2025-03-25T12:09:04.053531Z",
     "iopub.status.idle": "2025-03-25T12:09:04.060928Z",
     "shell.execute_reply": "2025-03-25T12:09:04.059961Z",
     "shell.execute_reply.started": "2025-03-25T12:09:04.053819Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0, grad_clip=None, opt_func=torch.optim.Adam):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []\n",
    "\n",
    "    # Set up custom optimizer with weight decay\n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "    # Set up one-cycle learning rate scheduler\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        for batch in tqdm(train_loader):\n",
    "            images, targets = batch\n",
    "            images, targets = images.to(device), targets.to(device)  # Move data to device\n",
    "            loss = model.training_step((images, targets))\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            if grad_clip:\n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Record & update learning rate\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            sched.step()\n",
    "\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history\n",
    "\n",
    "# Define the get_lr function (used in fit_one_cycle)\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T12:09:10.989052Z",
     "iopub.status.busy": "2025-03-25T12:09:10.988748Z",
     "iopub.status.idle": "2025-03-25T12:09:10.993758Z",
     "shell.execute_reply": "2025-03-25T12:09:10.992693Z",
     "shell.execute_reply.started": "2025-03-25T12:09:10.989028Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    for batch in val_loader:\n",
    "        images, targets = batch\n",
    "        images, targets = images.to(device), targets.to(device)  # Move data to device\n",
    "        outputs.append(model.validation_step((images, targets)))\n",
    "    return model.validation_epoch_end(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T12:09:23.020184Z",
     "iopub.status.busy": "2025-03-25T12:09:23.019871Z",
     "iopub.status.idle": "2025-03-25T12:09:23.024336Z",
     "shell.execute_reply": "2025-03-25T12:09:23.023387Z",
     "shell.execute_reply.started": "2025-03-25T12:09:23.020160Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "max_lr = 0.001\n",
    "grad_clip = 0.1\n",
    "weight_decay = 1e-4\n",
    "opt_func = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fit_one_cycle(epochs, max_lr, model, train_loader, val_loader,\n",
    "                         grad_clip=grad_clip, \n",
    "                         weight_decay=weight_decay, \n",
    "                         opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T13:27:46.932041Z",
     "iopub.status.busy": "2025-03-25T13:27:46.931722Z",
     "iopub.status.idle": "2025-03-25T13:27:46.948642Z",
     "shell.execute_reply": "2025-03-25T13:27:46.947646Z",
     "shell.execute_reply.started": "2025-03-25T13:27:46.932014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Attributes: ['black', 'shorts']\n"
     ]
    }
   ],
   "source": [
    "def predict_image(image_path):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img = transform(img).unsqueeze(0)  # Apply transformations and add batch dimension\n",
    "    img = img.to(device)  # Move image to device\n",
    "    output = model(img)\n",
    "    predicted_attributes = decode_target(output[0].cpu())  # Decode the output to get the predicted labels\n",
    "    return predicted_attributes\n",
    "\n",
    "# Example usage\n",
    "image_path = r\"/kaggle/input/apparel-dataset-test/ALL IMAGES/ALL IMAGES/black_shorts/005b19f2af0962b0a70455fbdc269a073ca3b0bf.jpg\"\n",
    "print(\"Predicted Attributes:\", predict_image(image_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T13:29:40.825894Z",
     "iopub.status.busy": "2025-03-25T13:29:40.825490Z",
     "iopub.status.idle": "2025-03-25T13:29:40.931452Z",
     "shell.execute_reply": "2025-03-25T13:29:40.930450Z",
     "shell.execute_reply.started": "2025-03-25T13:29:40.825847Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"SixthModel.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6963894,
     "sourceId": 11160714,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
