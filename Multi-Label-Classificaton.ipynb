{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11160714,"sourceType":"datasetVersion","datasetId":6963894}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"print(\"GPU IS READY\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Paths\nlocal_csv = r\"/kaggle/input/apparel-dataset-test/NEW_Main.csv\"  # Read-only CSV\nkaggle_csv = r\"/kaggle/working/New_Main.csv\"  # New CSV for Kaggle\n\n# Load the CSV in read-only mode\ndf = pd.read_csv(local_csv)\n\n# Path correction logic\nkaggle_base_path = \"/kaggle/input/apparel-dataset-test/ALL IMAGES/ALL IMAGES\"\n\n# Update paths\ndf[\"image path\"] = df.apply(\n    lambda row: f\"{kaggle_base_path}/{row['name']}/{row['image name']}\", axis=1\n)\n\n# Save the updated CSV for Kaggle\ndf.to_csv(kaggle_csv, index=False)\n\nprint(f\"✅ CSV saved successfully at: {kaggle_csv}\")\nprint(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T12:02:03.138999Z","iopub.execute_input":"2025-03-25T12:02:03.139378Z","iopub.status.idle":"2025-03-25T12:02:03.977858Z","shell.execute_reply.started":"2025-03-25T12:02:03.139344Z","shell.execute_reply":"2025-03-25T12:02:03.976730Z"}},"outputs":[{"name":"stdout","text":"✅ CSV saved successfully at: /kaggle/working/New_Main.csv\n                           name                            image name  \\\n0  black_checkered_casual_shirt  black_checkered_casual_shirt_100.jpg   \n1  black_checkered_casual_shirt  black_checkered_casual_shirt_102.jpg   \n2  black_checkered_casual_shirt  black_checkered_casual_shirt_104.jpg   \n3  black_checkered_casual_shirt  black_checkered_casual_shirt_106.jpg   \n4  black_checkered_casual_shirt  black_checkered_casual_shirt_108.jpg   \n\n                                          image path  \\\n0  /kaggle/input/apparel-dataset-test/ALL IMAGES/...   \n1  /kaggle/input/apparel-dataset-test/ALL IMAGES/...   \n2  /kaggle/input/apparel-dataset-test/ALL IMAGES/...   \n3  /kaggle/input/apparel-dataset-test/ALL IMAGES/...   \n4  /kaggle/input/apparel-dataset-test/ALL IMAGES/...   \n\n                     attributes  \n0  black,checkered,casual,shirt  \n1  black,checkered,casual,shirt  \n2  black,checkered,casual,shirt  \n3  black,checkered,casual,shirt  \n4  black,checkered,casual,shirt  \n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T12:02:22.189733Z","iopub.execute_input":"2025-03-25T12:02:22.190083Z","iopub.status.idle":"2025-03-25T12:02:22.200510Z","shell.execute_reply.started":"2025-03-25T12:02:22.190050Z","shell.execute_reply":"2025-03-25T12:02:22.199805Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                           name                            image name  \\\n0  black_checkered_casual_shirt  black_checkered_casual_shirt_100.jpg   \n1  black_checkered_casual_shirt  black_checkered_casual_shirt_102.jpg   \n2  black_checkered_casual_shirt  black_checkered_casual_shirt_104.jpg   \n3  black_checkered_casual_shirt  black_checkered_casual_shirt_106.jpg   \n4  black_checkered_casual_shirt  black_checkered_casual_shirt_108.jpg   \n\n                                          image path  \\\n0  /kaggle/input/apparel-dataset-test/ALL IMAGES/...   \n1  /kaggle/input/apparel-dataset-test/ALL IMAGES/...   \n2  /kaggle/input/apparel-dataset-test/ALL IMAGES/...   \n3  /kaggle/input/apparel-dataset-test/ALL IMAGES/...   \n4  /kaggle/input/apparel-dataset-test/ALL IMAGES/...   \n\n                     attributes  \n0  black,checkered,casual,shirt  \n1  black,checkered,casual,shirt  \n2  black,checkered,casual,shirt  \n3  black,checkered,casual,shirt  \n4  black,checkered,casual,shirt  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>image name</th>\n      <th>image path</th>\n      <th>attributes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>black_checkered_casual_shirt</td>\n      <td>black_checkered_casual_shirt_100.jpg</td>\n      <td>/kaggle/input/apparel-dataset-test/ALL IMAGES/...</td>\n      <td>black,checkered,casual,shirt</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>black_checkered_casual_shirt</td>\n      <td>black_checkered_casual_shirt_102.jpg</td>\n      <td>/kaggle/input/apparel-dataset-test/ALL IMAGES/...</td>\n      <td>black,checkered,casual,shirt</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>black_checkered_casual_shirt</td>\n      <td>black_checkered_casual_shirt_104.jpg</td>\n      <td>/kaggle/input/apparel-dataset-test/ALL IMAGES/...</td>\n      <td>black,checkered,casual,shirt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>black_checkered_casual_shirt</td>\n      <td>black_checkered_casual_shirt_106.jpg</td>\n      <td>/kaggle/input/apparel-dataset-test/ALL IMAGES/...</td>\n      <td>black,checkered,casual,shirt</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>black_checkered_casual_shirt</td>\n      <td>black_checkered_casual_shirt_108.jpg</td>\n      <td>/kaggle/input/apparel-dataset-test/ALL IMAGES/...</td>\n      <td>black,checkered,casual,shirt</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import os\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport torchvision.transforms as T\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T12:02:56.540909Z","iopub.execute_input":"2025-03-25T12:02:56.541281Z","iopub.status.idle":"2025-03-25T12:02:59.653206Z","shell.execute_reply.started":"2025-03-25T12:02:56.541248Z","shell.execute_reply":"2025-03-25T12:02:59.652065Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"csv_path = r\"/kaggle/working/New_Main.csv\"\nroot_dir = r\"/kaggle/input/apparel-dataset-test/ALL IMAGES/ALL IMAGES\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T12:03:01.965592Z","iopub.execute_input":"2025-03-25T12:03:01.966052Z","iopub.status.idle":"2025-03-25T12:03:01.969830Z","shell.execute_reply.started":"2025-03-25T12:03:01.966025Z","shell.execute_reply":"2025-03-25T12:03:01.968798Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"data = pd.read_csv(csv_path, on_bad_lines='skip')\ndata = data.dropna().reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T12:03:03.324387Z","iopub.execute_input":"2025-03-25T12:03:03.324692Z","iopub.status.idle":"2025-03-25T12:03:03.437286Z","shell.execute_reply.started":"2025-03-25T12:03:03.324669Z","shell.execute_reply":"2025-03-25T12:03:03.436596Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"colors = ['white', 'blue', 'black', 'red', 'green','brown']\ntypes = [\"t-shirt\", \"shirt\", \"polo\", \"formal shirt\", \"casual shirt\",\"dress\",\"pants\",\"shoes\",\"shorts\"]\npatterns = [\"plain\", \"checkered\", \"striped\", \"floral\", \"dotted\", \"printed\"]\nclasses = colors + types + patterns\nprint(\"Total classes:\", len(classes))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T12:03:04.999736Z","iopub.execute_input":"2025-03-25T12:03:05.000046Z","iopub.status.idle":"2025-03-25T12:03:05.005468Z","shell.execute_reply.started":"2025-03-25T12:03:05.000021Z","shell.execute_reply":"2025-03-25T12:03:05.004434Z"}},"outputs":[{"name":"stdout","text":"Total classes: 21\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Function to encode labels from CSV\ndef encode_label(label, classes_list=classes):\n    target = torch.zeros(len(classes_list))\n    for l in label.split(\",\"):  # Ensure proper splitting by comma\n        l = l.strip()  # Remove any leading/trailing spaces\n        if l in classes_list:\n            idx = classes_list.index(l)\n            target[idx] = 1\n    return target\n\n# Apply encoding to the dataset\ndata[\"encoded_target\"] = data[\"attributes\"].apply(encode_label)\n\n# Decode labels for verification\ndef decode_target(target, threshold=0.4):\n    result = []\n    for i, x in enumerate(target):\n        if x >= threshold:\n            result.append(classes[i])\n    return result\n\n# Verify the encoding\nprint(data[[\"attributes\", \"encoded_target\"]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T12:03:06.913178Z","iopub.execute_input":"2025-03-25T12:03:06.913551Z","iopub.status.idle":"2025-03-25T12:03:07.783576Z","shell.execute_reply.started":"2025-03-25T12:03:06.913523Z","shell.execute_reply":"2025-03-25T12:03:07.782756Z"}},"outputs":[{"name":"stdout","text":"                         attributes  \\\n0      black,checkered,casual,shirt   \n1      black,checkered,casual,shirt   \n2      black,checkered,casual,shirt   \n3      black,checkered,casual,shirt   \n4      black,checkered,casual,shirt   \n...                             ...   \n37713         white,striped,t-shirt   \n37714         white,striped,t-shirt   \n37715         white,striped,t-shirt   \n37716         white,striped,t-shirt   \n37717         white,striped,t-shirt   \n\n                                          encoded_target  \n0      [tensor(0.), tensor(0.), tensor(1.), tensor(0....  \n1      [tensor(0.), tensor(0.), tensor(1.), tensor(0....  \n2      [tensor(0.), tensor(0.), tensor(1.), tensor(0....  \n3      [tensor(0.), tensor(0.), tensor(1.), tensor(0....  \n4      [tensor(0.), tensor(0.), tensor(1.), tensor(0....  \n...                                                  ...  \n37713  [tensor(1.), tensor(0.), tensor(0.), tensor(0....  \n37714  [tensor(1.), tensor(0.), tensor(0.), tensor(0....  \n37715  [tensor(1.), tensor(0.), tensor(0.), tensor(0....  \n37716  [tensor(1.), tensor(0.), tensor(0.), tensor(0....  \n37717  [tensor(1.), tensor(0.), tensor(0.), tensor(0....  \n\n[37718 rows x 2 columns]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\ntransform = T.Compose([\n    T.Resize((128, 128)),\n    T.RandomHorizontalFlip(),\n    T.RandomRotation(2),\n    T.ToTensor(),\n    T.Normalize(*imagenet_stats)\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T12:03:11.713734Z","iopub.execute_input":"2025-03-25T12:03:11.714062Z","iopub.status.idle":"2025-03-25T12:03:11.718643Z","shell.execute_reply.started":"2025-03-25T12:03:11.714032Z","shell.execute_reply":"2025-03-25T12:03:11.717746Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, data, root_dir, transform=None):\n        self.data = data\n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_name = self.data.iloc[idx]['image path'].strip()\n        img_path = os.path.join(self.root_dir, img_name)\n\n        # Check if image exists\n        if not os.path.exists(img_path):\n            print(f\"Missing image: {img_path}\")\n            return torch.zeros(3, 128, 128), torch.zeros(len(classes))  # Dummy data\n\n        try:\n            img = Image.open(img_path).convert(\"RGB\")\n        except Exception as e:\n            print(f\"Error loading image {img_path}: {e}\")\n            return torch.zeros(3, 128, 128), torch.zeros(len(classes))  # Return dummy data\n\n        if self.transform:\n            img = self.transform(img)\n\n        # Get label from CSV\n        label = self.data.iloc[idx][\"encoded_target\"]\n\n        # Ensure label is a tensor\n        if isinstance(label, str):\n            label = torch.tensor(eval(label), dtype=torch.float32)  # Convert stringified tensor to tensor\n        else:\n            label = torch.tensor(label, dtype=torch.float32)\n\n        return img, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T12:03:13.618459Z","iopub.execute_input":"2025-03-25T12:03:13.618794Z","iopub.status.idle":"2025-03-25T12:03:13.625426Z","shell.execute_reply.started":"2025-03-25T12:03:13.618764Z","shell.execute_reply":"2025-03-25T12:03:13.624567Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"dataset = MyDataset(data, root_dir, transform=transform)\ntrain_ds, val_ds = train_test_split(dataset, test_size=0.15, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T12:03:21.086278Z","iopub.execute_input":"2025-03-25T12:03:21.086607Z","iopub.status.idle":"2025-03-25T12:07:57.809672Z","shell.execute_reply.started":"2025-03-25T12:03:21.086581Z","shell.execute_reply":"2025-03-25T12:07:57.808861Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"batch_size = 32\ntrain_loader = DataLoader(train_ds, batch_size, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size * 2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T12:08:35.838618Z","iopub.execute_input":"2025-03-25T12:08:35.838936Z","iopub.status.idle":"2025-03-25T12:08:35.843474Z","shell.execute_reply.started":"2025-03-25T12:08:35.838912Z","shell.execute_reply":"2025-03-25T12:08:35.842422Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def F_score(output, label, threshold=0.7, beta=1):  \n    prob = output > threshold\n    label = label > threshold\n\n    TP = (prob & label).sum(1).float()\n    FP = (prob & (~label)).sum(1).float()\n    FN = ((~prob) & label).sum(1).float()\n\n    precision = torch.mean(TP / (TP + FP + 1e-12))\n    recall = torch.mean(TP / (TP + FN + 1e-12))\n    F2 = (1 + beta**2) * precision * recall / (beta**2 * precision + recall + 1e-12)\n    return F2.mean(0)\n\n# Model Training Base Class\nclass MultilabelImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, targets = batch \n        out = self(images)                            \n        loss = F.binary_cross_entropy(out, targets)   \n        return loss    \n\n    def validation_step(self, batch):\n        images, targets = batch \n        out = self(images)                           \n        loss = F.binary_cross_entropy(out, targets)  \n        score = F_score(out, targets)                \n        return {'val_loss': loss.detach(), 'val_score': score.detach()}      \n\n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()       \n        batch_scores = [x['val_score'] for x in outputs]    \n        epoch_score = torch.stack(batch_scores).mean()      \n        return {'val_loss': epoch_loss.item(), 'val_score': epoch_score.item()}    \n\n    def epoch_end(self, epoch, result):                     \n        print(\"Epoch [{}], last_lr: {:.4f}, train_loss: {:.4f}, val_loss: {:.4f}, val_score: {:.4f}\".format(\n            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_score']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T12:08:42.563814Z","iopub.execute_input":"2025-03-25T12:08:42.564149Z","iopub.status.idle":"2025-03-25T12:08:42.572452Z","shell.execute_reply.started":"2025-03-25T12:08:42.564118Z","shell.execute_reply":"2025-03-25T12:08:42.571491Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class ResNet15(MultilabelImageClassificationBase):\n    def __init__(self, in_channels, num_classes):\n        super().__init__()     \n        # Input 3 x 128 x 128\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True)\n        )\n        self.res1 = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True)\n        )\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.MaxPool2d(4),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True)\n        )\n        self.res2 = nn.Sequential(\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True)\n        )\n        self.conv3 = nn.Sequential(\n            nn.Conv2d(128, 512, kernel_size=3, padding=1),\n            nn.MaxPool2d(4),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True)\n        )\n        self.res3 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True)\n        )\n        self.conv4 = nn.Sequential(\n            nn.Conv2d(512, 1024, kernel_size=3, padding=1),\n            nn.MaxPool2d(4),\n            nn.BatchNorm2d(1024),\n            nn.ReLU(inplace=True)\n        )\n        self.res4 = nn.Sequential(\n            nn.Conv2d(1024, 1024, kernel_size=3, padding=1),\n            nn.BatchNorm2d(1024),\n            nn.ReLU(inplace=True)\n        )\n        self.classifier = nn.Sequential(\n            nn.MaxPool2d(2),\n            nn.Flatten(),\n            nn.Dropout(0.2),\n            nn.Linear(1024 * 1 * 1, 512),\n            nn.ReLU(),\n            nn.Linear(512, num_classes)\n        )\n\n    def forward(self, xb):\n        out = self.conv1(xb)\n        out = self.res1(out) + out\n        out = self.conv2(out)\n        out = self.res2(out) + out\n        out = self.conv3(out)\n        out = self.res3(out) + out\n        out = self.conv4(out)\n        out = self.res4(out) + out\n        out = self.classifier(out)\n        out = torch.sigmoid(out)  # Use sigmoid for multi-label classification\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T12:08:49.539746Z","iopub.execute_input":"2025-03-25T12:08:49.540073Z","iopub.status.idle":"2025-03-25T12:08:49.549394Z","shell.execute_reply.started":"2025-03-25T12:08:49.540047Z","shell.execute_reply":"2025-03-25T12:08:49.548408Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = ResNet15(3, len(classes)).to(device)\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T12:08:57.136661Z","iopub.execute_input":"2025-03-25T12:08:57.137086Z","iopub.status.idle":"2025-03-25T12:08:57.591093Z","shell.execute_reply.started":"2025-03-25T12:08:57.137049Z","shell.execute_reply":"2025-03-25T12:08:57.590302Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0, grad_clip=None, opt_func=torch.optim.Adam):\n    torch.cuda.empty_cache()\n    history = []\n\n    # Set up custom optimizer with weight decay\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    # Set up one-cycle learning rate scheduler\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader))\n\n    for epoch in range(epochs):\n        # Training Phase\n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in tqdm(train_loader):\n            images, targets = batch\n            images, targets = images.to(device), targets.to(device)  # Move data to device\n            loss = model.training_step((images, targets))\n            train_losses.append(loss)\n            loss.backward()\n\n            # Gradient clipping\n            if grad_clip:\n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n\n            optimizer.step()\n            optimizer.zero_grad()\n\n            # Record & update learning rate\n            lrs.append(get_lr(optimizer))\n            sched.step()\n\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history\n\n# Define the get_lr function (used in fit_one_cycle)\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T12:09:04.053531Z","iopub.execute_input":"2025-03-25T12:09:04.053842Z","iopub.status.idle":"2025-03-25T12:09:04.060928Z","shell.execute_reply.started":"2025-03-25T12:09:04.053819Z","shell.execute_reply":"2025-03-25T12:09:04.059961Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = []\n    for batch in val_loader:\n        images, targets = batch\n        images, targets = images.to(device), targets.to(device)  # Move data to device\n        outputs.append(model.validation_step((images, targets)))\n    return model.validation_epoch_end(outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T12:09:10.988748Z","iopub.execute_input":"2025-03-25T12:09:10.989052Z","iopub.status.idle":"2025-03-25T12:09:10.993758Z","shell.execute_reply.started":"2025-03-25T12:09:10.989028Z","shell.execute_reply":"2025-03-25T12:09:10.992693Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"epochs = 50\nmax_lr = 0.001\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.Adam","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T12:09:23.019871Z","iopub.execute_input":"2025-03-25T12:09:23.020184Z","iopub.status.idle":"2025-03-25T12:09:23.024336Z","shell.execute_reply.started":"2025-03-25T12:09:23.020160Z","shell.execute_reply":"2025-03-25T12:09:23.023387Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"history = fit_one_cycle(epochs, max_lr, model, train_loader, val_loader,\n                         grad_clip=grad_clip, \n                         weight_decay=weight_decay, \n                         opt_func=opt_func)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T12:09:31.297547Z","iopub.execute_input":"2025-03-25T12:09:31.297849Z","iopub.status.idle":"2025-03-25T13:26:36.182016Z","shell.execute_reply.started":"2025-03-25T12:09:31.297826Z","shell.execute_reply":"2025-03-25T13:26:36.181103Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc3b8e339544429dbbac35725e6906d4"}},"metadata":{}},{"name":"stdout","text":"Epoch [0], last_lr: 0.0001, train_loss: 0.2412, val_loss: 0.1977, val_score: 0.5677\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e2ede51b4b64f0e891800105373bd90"}},"metadata":{}},{"name":"stdout","text":"Epoch [1], last_lr: 0.0001, train_loss: 0.1867, val_loss: 0.1775, val_score: 0.6372\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"142bba4ca021427aabf419ec1a5b0bd8"}},"metadata":{}},{"name":"stdout","text":"Epoch [2], last_lr: 0.0001, train_loss: 0.1680, val_loss: 0.1657, val_score: 0.6607\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"408780da428c4cae8e0099cba49a4bdd"}},"metadata":{}},{"name":"stdout","text":"Epoch [3], last_lr: 0.0002, train_loss: 0.1566, val_loss: 0.1600, val_score: 0.6572\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2db75bb8adbb4ee694dd9eece2d2ed0c"}},"metadata":{}},{"name":"stdout","text":"Epoch [4], last_lr: 0.0003, train_loss: 0.1490, val_loss: 0.1538, val_score: 0.7060\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd52837abaaa4bdebea4964160f3f153"}},"metadata":{}},{"name":"stdout","text":"Epoch [5], last_lr: 0.0004, train_loss: 0.1442, val_loss: 0.1548, val_score: 0.6982\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cb515fe86484db389d9d4a1c1a13c31"}},"metadata":{}},{"name":"stdout","text":"Epoch [6], last_lr: 0.0005, train_loss: 0.1416, val_loss: 0.1538, val_score: 0.6908\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d97e2e598ca741e39c419db4f99020c0"}},"metadata":{}},{"name":"stdout","text":"Epoch [7], last_lr: 0.0006, train_loss: 0.1416, val_loss: 0.1531, val_score: 0.7105\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ceb6121742ae43839f7b3b90d281477f"}},"metadata":{}},{"name":"stdout","text":"Epoch [8], last_lr: 0.0007, train_loss: 0.1427, val_loss: 0.1541, val_score: 0.6982\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9bb4eca2e554412ba450c698b35405d"}},"metadata":{}},{"name":"stdout","text":"Epoch [9], last_lr: 0.0008, train_loss: 0.1425, val_loss: 0.1612, val_score: 0.6754\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc274bbb014e405286d2f585579edc9a"}},"metadata":{}},{"name":"stdout","text":"Epoch [10], last_lr: 0.0008, train_loss: 0.1436, val_loss: 0.1547, val_score: 0.6735\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cda3d53a307146ae9c2aa5dee2f84e31"}},"metadata":{}},{"name":"stdout","text":"Epoch [11], last_lr: 0.0009, train_loss: 0.1429, val_loss: 0.1560, val_score: 0.6818\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97c9d538132249efa385ccb86a6f6ad9"}},"metadata":{}},{"name":"stdout","text":"Epoch [12], last_lr: 0.0010, train_loss: 0.1424, val_loss: 0.1532, val_score: 0.7120\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6aec65d38983477eb5e8f4bb37e181c5"}},"metadata":{}},{"name":"stdout","text":"Epoch [13], last_lr: 0.0010, train_loss: 0.1404, val_loss: 0.1463, val_score: 0.7047\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08601b08299047c59e80ea6103e147aa"}},"metadata":{}},{"name":"stdout","text":"Epoch [14], last_lr: 0.0010, train_loss: 0.1388, val_loss: 0.1443, val_score: 0.7203\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cc968e6a4854f279a31735df3030c1e"}},"metadata":{}},{"name":"stdout","text":"Epoch [15], last_lr: 0.0010, train_loss: 0.1365, val_loss: 0.1420, val_score: 0.7182\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a6abb89b8884403967649e1fc336cec"}},"metadata":{}},{"name":"stdout","text":"Epoch [16], last_lr: 0.0010, train_loss: 0.1345, val_loss: 0.1436, val_score: 0.7186\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8903e6b39a104409a8050b800860bbfa"}},"metadata":{}},{"name":"stdout","text":"Epoch [17], last_lr: 0.0010, train_loss: 0.1320, val_loss: 0.1436, val_score: 0.7245\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ce14ae1516e460a9deff57ab0dda7aa"}},"metadata":{}},{"name":"stdout","text":"Epoch [18], last_lr: 0.0010, train_loss: 0.1290, val_loss: 0.1433, val_score: 0.7264\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"317e6a2e392b44db935173de58698ed5"}},"metadata":{}},{"name":"stdout","text":"Epoch [19], last_lr: 0.0010, train_loss: 0.1271, val_loss: 0.1433, val_score: 0.7231\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1673af33b4324bccaef1e3b6c18a62f6"}},"metadata":{}},{"name":"stdout","text":"Epoch [20], last_lr: 0.0009, train_loss: 0.1237, val_loss: 0.1482, val_score: 0.7342\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c4d6061cf8d442d868ec99606ca9e65"}},"metadata":{}},{"name":"stdout","text":"Epoch [21], last_lr: 0.0009, train_loss: 0.1204, val_loss: 0.1410, val_score: 0.7482\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1e442c97ccf4c1fb76483554cece6d2"}},"metadata":{}},{"name":"stdout","text":"Epoch [22], last_lr: 0.0009, train_loss: 0.1174, val_loss: 0.1402, val_score: 0.7460\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fd3f606385340bd939feef83b079607"}},"metadata":{}},{"name":"stdout","text":"Epoch [23], last_lr: 0.0008, train_loss: 0.1139, val_loss: 0.1396, val_score: 0.7386\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99143f55322849fc9864f0b40d394419"}},"metadata":{}},{"name":"stdout","text":"Epoch [24], last_lr: 0.0008, train_loss: 0.1103, val_loss: 0.1463, val_score: 0.7512\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b72ad32cc5e4fb494724ba08ab59c58"}},"metadata":{}},{"name":"stdout","text":"Epoch [25], last_lr: 0.0008, train_loss: 0.1058, val_loss: 0.1443, val_score: 0.7530\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0722817ea96b4ab19df994e5915482bc"}},"metadata":{}},{"name":"stdout","text":"Epoch [26], last_lr: 0.0007, train_loss: 0.1016, val_loss: 0.1457, val_score: 0.7597\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ef7741b33e64ff0ba9cb264fd4d8d7a"}},"metadata":{}},{"name":"stdout","text":"Epoch [27], last_lr: 0.0007, train_loss: 0.0955, val_loss: 0.1484, val_score: 0.7551\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec721e4dcbe34dc4a81433d741196a39"}},"metadata":{}},{"name":"stdout","text":"Epoch [28], last_lr: 0.0007, train_loss: 0.0895, val_loss: 0.1548, val_score: 0.7680\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cf97dfa4fc542b9913d4b9dc7b116b8"}},"metadata":{}},{"name":"stdout","text":"Epoch [29], last_lr: 0.0006, train_loss: 0.0833, val_loss: 0.1539, val_score: 0.7646\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"932cd234f7764c4ab571bf43e494ccb1"}},"metadata":{}},{"name":"stdout","text":"Epoch [30], last_lr: 0.0006, train_loss: 0.0768, val_loss: 0.1612, val_score: 0.7616\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42c0404c8d284722b7242d22351863a3"}},"metadata":{}},{"name":"stdout","text":"Epoch [31], last_lr: 0.0005, train_loss: 0.0690, val_loss: 0.1617, val_score: 0.7592\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04a4d2ec791a4915945c739b9befdc92"}},"metadata":{}},{"name":"stdout","text":"Epoch [32], last_lr: 0.0005, train_loss: 0.0619, val_loss: 0.1748, val_score: 0.7599\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f7728828ae04df781f550b8041234dc"}},"metadata":{}},{"name":"stdout","text":"Epoch [33], last_lr: 0.0004, train_loss: 0.0527, val_loss: 0.1900, val_score: 0.7610\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4535d4aa48754b27ac492a831e4e3fe7"}},"metadata":{}},{"name":"stdout","text":"Epoch [34], last_lr: 0.0004, train_loss: 0.0454, val_loss: 0.1944, val_score: 0.7609\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5447e0a558e4530ba49313db011ea15"}},"metadata":{}},{"name":"stdout","text":"Epoch [35], last_lr: 0.0003, train_loss: 0.0389, val_loss: 0.2036, val_score: 0.7644\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15e01c4e11804f7c9ae874f07b737271"}},"metadata":{}},{"name":"stdout","text":"Epoch [36], last_lr: 0.0003, train_loss: 0.0328, val_loss: 0.2101, val_score: 0.7623\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bb89b6a0d3b460c8743914374731c1b"}},"metadata":{}},{"name":"stdout","text":"Epoch [37], last_lr: 0.0003, train_loss: 0.0260, val_loss: 0.2309, val_score: 0.7649\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdfe659c1af34a95b8d6c1bf21fc09c4"}},"metadata":{}},{"name":"stdout","text":"Epoch [38], last_lr: 0.0002, train_loss: 0.0203, val_loss: 0.2354, val_score: 0.7653\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34c002f882b440aa9ec7bfba99d04c3e"}},"metadata":{}},{"name":"stdout","text":"Epoch [39], last_lr: 0.0002, train_loss: 0.0171, val_loss: 0.2451, val_score: 0.7649\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0d0d6a90cf440fe89527bf06ef68f72"}},"metadata":{}},{"name":"stdout","text":"Epoch [40], last_lr: 0.0002, train_loss: 0.0140, val_loss: 0.2498, val_score: 0.7668\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef016bcf3d4447479d0b7fb7ed552af3"}},"metadata":{}},{"name":"stdout","text":"Epoch [41], last_lr: 0.0001, train_loss: 0.0110, val_loss: 0.2597, val_score: 0.7692\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54eb274b22a84ce48ed0ee27006cf829"}},"metadata":{}},{"name":"stdout","text":"Epoch [42], last_lr: 0.0001, train_loss: 0.0089, val_loss: 0.2686, val_score: 0.7682\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ce3dabd809548a6982a9da1b5e90a38"}},"metadata":{}},{"name":"stdout","text":"Epoch [43], last_lr: 0.0001, train_loss: 0.0073, val_loss: 0.2749, val_score: 0.7695\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e941f5528a3a44fab269846ad5e2ca06"}},"metadata":{}},{"name":"stdout","text":"Epoch [44], last_lr: 0.0000, train_loss: 0.0061, val_loss: 0.2719, val_score: 0.7684\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc98b409c25a40d8bb1509ff3b8552f9"}},"metadata":{}},{"name":"stdout","text":"Epoch [45], last_lr: 0.0000, train_loss: 0.0052, val_loss: 0.2776, val_score: 0.7684\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"977d70ef95e04e79be52cc595e26425d"}},"metadata":{}},{"name":"stdout","text":"Epoch [46], last_lr: 0.0000, train_loss: 0.0045, val_loss: 0.2765, val_score: 0.7724\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b92f7a3124745a6af405d2b8d031427"}},"metadata":{}},{"name":"stdout","text":"Epoch [47], last_lr: 0.0000, train_loss: 0.0039, val_loss: 0.2776, val_score: 0.7692\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3028d0e83bd43c4b323fcc125330b9e"}},"metadata":{}},{"name":"stdout","text":"Epoch [48], last_lr: 0.0000, train_loss: 0.0038, val_loss: 0.2773, val_score: 0.7706\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1bcca2b954e432a816f78740b352e9c"}},"metadata":{}},{"name":"stdout","text":"Epoch [49], last_lr: 0.0000, train_loss: 0.0037, val_loss: 0.2822, val_score: 0.7697\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"def predict_image(image_path):\n    img = Image.open(image_path).convert(\"RGB\")\n    img = transform(img).unsqueeze(0)  # Apply transformations and add batch dimension\n    img = img.to(device)  # Move image to device\n    output = model(img)\n    predicted_attributes = decode_target(output[0].cpu())  # Decode the output to get the predicted labels\n    return predicted_attributes\n\n# Example usage\nimage_path = r\"/kaggle/input/apparel-dataset-test/ALL IMAGES/ALL IMAGES/black_shorts/005b19f2af0962b0a70455fbdc269a073ca3b0bf.jpg\"\nprint(\"Predicted Attributes:\", predict_image(image_path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T13:27:46.931722Z","iopub.execute_input":"2025-03-25T13:27:46.932041Z","iopub.status.idle":"2025-03-25T13:27:46.948642Z","shell.execute_reply.started":"2025-03-25T13:27:46.932014Z","shell.execute_reply":"2025-03-25T13:27:46.947646Z"}},"outputs":[{"name":"stdout","text":"Predicted Attributes: ['black', 'shorts']\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"torch.save(model.state_dict(), \"SixthModel.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T13:29:40.825490Z","iopub.execute_input":"2025-03-25T13:29:40.825894Z","iopub.status.idle":"2025-03-25T13:29:40.931452Z","shell.execute_reply.started":"2025-03-25T13:29:40.825847Z","shell.execute_reply":"2025-03-25T13:29:40.930450Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}